export default async function handler(req, res) {
  const { message } = await req.body;

  const prompt = `ä½ æ˜¯æ³•å¾‹åŠ©ç†ï¼Œä»¥ä¸‹æ˜¯å››ä½å¾‹å¸«åŠå…¶å°ˆé•·ï¼š
- æ—å¾‹å¸«ï¼šå•†æ¨™ã€æ™ºæ…§è²¡ç”¢æ¬Š
- åŠ‰å¾‹å¸«ï¼šä¸€èˆ¬åˆ‘æ¡ˆã€é™ªåµ
- å¼µå¾‹å¸«ï¼šé‡å¤§åˆ‘æ¡ˆ
- æ›¾å¾‹å¸«ï¼šæ°‘äº‹ã€å®¶äº‹ã€èª¿è§£

è«‹é‡å°ä»¥ä¸‹æ³•å¾‹å•é¡Œï¼Œç™½è©±è§£é‡‹ä¸¦æ¨è–¦å¾‹å¸«ï¼šã€Œ${message}ã€`;

  const openaiRes = await fetch("https://api.openai.com/v1/chat/completions", {
    method: "POST",
    headers: {
      "Content-Type": "application/json",
      Authorization: "Bearer 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"  // ğŸ” é€™è£¡æ”¹æˆä½ çš„ project key
    },
    body: JSON.stringify({
      model: "gpt-3.5-turbo",
      messages: [
        { role: "system", content: "ä½ æ˜¯å°ä¸­æ³•å¾‹è«®è©¢ç¶²ç«™å®¢æœ" },
        { role: "user", content: prompt }
      ]
    })
  });

  const data = await openaiRes.json();
  res.status(200).json({ text: data.choices?.[0]?.message?.content || "âš ï¸ ç„¡æ³•å›è¦†" });
}
